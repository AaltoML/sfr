# _target_: models.reward.gp.GPRewardModel
# likelihood:
#   _target_: gpytorch.likelihoods.GaussianLikelihood
# mean_module:
#   _target_: gpytorch.means.ConstantMean
# covar_module:
#   _target_: gpytorch.kernels.ScaleKernel
#   base_kernel:
#     _target_: gpytorch.kernels.RBFKernel
#     ard_num_dims: ${state_dim}
# num_inducing: 128
# batch_size: 64
# learning_rate: 0.01
# # num_iterations: 1000
# num_iterations: 5000
# # num_iterations: 5
# # num_iterations: 500
# num_workers: 1
# learn_inducing_locations: False

_target_: models.reward.build_SVGPRewardModel
_convert_: all
svgp:
  _target_: models.svgp.SVGP
  inducing_points:
    _target_: torch.rand
    size:
      # - 1
      - 500 # num_inducing
      - ${input_dim}
  mean_module:
    _target_: gpytorch.means.ConstantMean
  covar_module:
    _target_: gpytorch.kernels.ScaleKernel
    base_kernel:
      _target_: gpytorch.kernels.RBFKernel
      ard_num_dims: ${input_dim}
  learn_inducing_locations: true
likelihood:
  _target_: gpytorch.likelihoods.GaussianLikelihood
# learning_rate: 0.05
learning_rate: 0.1
batch_size: 64
# num_epochs: 2000
num_epochs: 300
num_workers: 1 # TODO what should I set this to?
wandb_loss_name: "Reward model loss"
early_stopper:
  _target_: utils.EarlyStopper
  patience: 20
  min_delta: 0
