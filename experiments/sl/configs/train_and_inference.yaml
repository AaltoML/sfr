defaults:
  - network: si_mlp
  - dataset: australian
  # Use slurm on cluster or local?
  # - override hydra/launcher: submitit_local
  - override hydra/launcher: lumi
  # - override hydra/launcher: puhti
  # - override hydra/launcher: slurm
  # Disable logging by Hydra
  # - override hydra/job_logging: none # stop hydra creating .log file
  # - override hydra/hydra_logging: none # saves .hydra/*.yaml files
  - _self_

# posthoc_prior_opt: False
posthoc_prior_opt: True
dual_batch_size: 5000
EPS: 0.0
jitter: 1e-6

num_inducings:
  - 16
  - 32
  - 64
  - 128
  - 256
  - 512

device: "cuda"
# device: "cpu"
output_dim: ???
batch_size: 512
lr: 1e-4
n_epochs: 500
double: False

logging_epoch_freq: 2
random_seed: 117

early_stop:
  patience: 15
  min_delta: 0

sfr:
  _target_: experiments.sl.utils.init_SFR_with_gaussian_prior
  _convert_: all
  # network: ???
  delta: 1e-4
  likelihood:
    _target_: src.likelihoods.CategoricalLh
    EPS: 0.0 # TODO default is 0.01
  output_dim: ${output_dim}
  num_inducing: 128
  dual_batch_size: 1000
  jitter: 1e-4
  device: ${device} # TODO should this always be cpu??

wandb:
  group: ${dataset.name}
  project: "sl-train-and-inference"
  use_wandb: True
  run_name: ${dataset.name}-seed=${random_seed}-${now:%Y-%m-%d_%H-%M-%S}
  tags:
    - "dataset=${dataset.name}"
    - "seed=${random_seed}"

hydra:
  run:
    dir: output/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: true
  sweep:
    dir: ${hydra.run.dir}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO # DEBUG
