_target_: experiments.rl.models.rewards.svgp.init
_convert_: all
svgp:
  _target_: experiments.rl.models.svgp.SVGP
  _convert_: all
  inducing_points:
    _target_: torch.rand
    size:
      # - 500 # num_inducing
      # - 128 # num_inducing
      - 256 # num_inducing
      - ${input_dim}
  mean_module:
    _target_: gpytorch.means.ConstantMean
  covar_module:
    _target_: gpytorch.kernels.ScaleKernel
    base_kernel:
      _target_: gpytorch.kernels.RBFKernel
      ard_num_dims: ${input_dim}
  learn_inducing_locations: true # TODO turn this back on?
  # learn_inducing_locations: false
  device: ${device}
  likelihood:
    _target_: gpytorch.likelihoods.GaussianLikelihood
# learning_rate: 0.05
learning_rate: 0.1
batch_size: 64
num_epochs: 2000
# num_epochs: 300
# num_workers: 1 # TODO what should I set this to?
# wandb_loss_name: "Reward model loss"
wandb_loss_name: "model/reward_loss"
early_stopper:
  _target_: utils.EarlyStopper
  # patience: 20
  patience: 100
  min_delta: 0
device: ${device} # TODO should this always be cpu??
