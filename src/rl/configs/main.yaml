defaults:
  - reward_model: mlp
  # - transition_model: mlp
  # - reward_model: svgp
  # - transition_model: svgp
  # - reward_model: nn2svgp
  - transition_model: nn2svgp
  # - agent: ddpg
  - agent: mppi
  - env: cartpole_swingup
  # - env: cheetah_run
  # Use slurm on cluster or local?
  # - override hydra/launcher: submitit_local
  # - override hydra/launcher: local
  # - override hydra/launcher: lumi
  - override hydra/launcher: slurm
  # Disable logging by Hydra
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none
  - _self_

state_dim: ???
action_dim: ???
input_dim: ???
output_dim: ???
device: ???

online_updates: false
online_update_freq: 2
# online_update_freq: 50

alg_name: "mppi-svgp"
random_seed: 42

# init_random_episodes: 10
init_random_episodes: 1
num_train_episodes: 2000
# episode_length: 1000
episode_length: 100
update_every_steps: 2

# eval_episode_freq: 10
eval_episode_freq: 2
# save_video: true
save_video: false

replay_buffer_capacity: 100000
save_buffer: false
buffer_scratch_dir: "/tmp/"
batch_size: 512

wandb:
  group: ${env.env_name}-${env.task_name}
  # group: ${env.env_name}
  entity: "aidanscannell"
  project: "bayesian-model-based-rl-with-fast-updates"
  use_wandb: True
  run_name: ${alg_name}-${online_update_freq}-seed=${random_seed}-${now:%Y-%m-%d_%H-%M-%S}
  # run_name: ${alg_name}-${online_update_freq}-${agent.horizon}-${random_seed}-${now:%Y-%m-%d_%H-%M-%S}
  tags:
    - "random_seed=${random_seed}"
    - "env=${env.env_name}-${env.task_name}"
    - "alg=${alg_name}"
    - "online_update_freq=${online_update_freq}"
    # - "horizon=${agent.horizon}"
    # - "num_samples=${agent.num_samples}"

hydra:
  job:
    chdir: False
  run:
    dir: ""
