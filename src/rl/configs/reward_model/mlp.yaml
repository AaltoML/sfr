_target_: src.rl.models.rewards.mlp.init
_convert_: all
network: ${reward_network}
learning_rate: 1e-3
num_iterations: 5000
batch_size: 64
# num_workers: 1 # TODO what should I set this to?
wandb_loss_name: "reward/loss"
# early_stopper:
#   _target_: src.rl.utils.EarlyStopper
#   patience: 50
#   min_delta: 0
device: ${device} # TODO should this always be cpu??
