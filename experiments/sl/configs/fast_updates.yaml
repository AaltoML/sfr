defaults:
  - network: si_mlp
  - dataset: australian
  # Use slurm on cluster or local?
  # - override hydra/launcher: submitit_local
  - override hydra/launcher: lumi
  # - override hydra/launcher: puhti
  # - override hydra/launcher: slurm
  # Disable logging by Hydra
  # - override hydra/job_logging: none # stop hydra creating .log file
  # - override hydra/hydra_logging: none # saves .hydra/*.yaml files
  - _self_

train_update_split: 0.5

device: "cuda"
# device: "cpu"
output_dim: ???
batch_size: 512
lr: 1e-4
n_epochs: 10000
double: False
double_inference: True # True for UCI and False for MNIST/FMNIST/CIFAR10

logging_epoch_freq: 2
random_seed: 117

early_stop:
  patience: 1000
  min_prior_precision: 0

sfr:
  _target_: experiments.sl.utils.init_SFR_with_gaussian_prior
  _convert_: all
  prior_precision: 0.008
  likelihood:
    _target_: src.likelihoods.CategoricalLh
    # EPS: 0.001 # TODO default is 0.01
    EPS: 0.0 # TODO default is 0.01
  output_dim: ${output_dim}
  # num_inducing: 128
  num_inducing: 256
  dual_batch_size: 1000
  jitter: 1e-4
  device: ${device} # TODO should this always be cpu??

wandb:
  group: ${dataset.name}
  project: "sl-fast-updates"
  use_wandb: True
  run_name: ${dataset.name}-seed=${random_seed}-${now:%Y-%m-%d_%H-%M-%S}
  tags:
    - "dataset=${dataset.name}"
    - "seed=${random_seed}"

hydra:
  run:
    dir: output/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: true
  sweep:
    dir: ${hydra.run.dir}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO # DEBUG
