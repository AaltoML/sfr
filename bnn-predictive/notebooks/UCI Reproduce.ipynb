{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "cce7f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "from torch.optim import Adam\n",
    "from torch.distributions import MultivariateNormal, Normal\n",
    "from preds.models import MLPS\n",
    "\n",
    "from preds.likelihoods import CategoricalLh\n",
    "from preds.datasets import UCIClassificationDatasets\n",
    "from preds.laplace import Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf8dc32",
   "metadata": {},
   "source": [
    "Includes some playing around with the Immer et al. dataset and model classes and a script for running the UCI experiemnts (with hyperparameters as in the paper appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bc00ad",
   "metadata": {},
   "source": [
    "Testing the dataset and model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd036c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 50 # as in Immer et al. \n",
    "depth = 2 # as in Immer et al. \n",
    "prior_prec = np.logspace(-2, 2, num=10)[0] # as in Immer et al. but depends on dataset\n",
    "lr = 1e-3 # as in Immer et al. \n",
    "n_epochs = 10000\n",
    "n_samples = 1000\n",
    "train_size = 0.70 # as in Immer et al. \n",
    "lh = CateoricalLh()  \n",
    "uci_dataset = 'glass'\n",
    "root_dir = '../data/'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbdd49f",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b75edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = UCIClassificationDatasets(train=True, data_set=uci_dataset, split_train_size=train_size, double=False, root=root_dir)\n",
    "X_train, y_train = ds_train.data.to(device), ds_train.targets.to(device).unsqueeze(1)\n",
    "train_loader = [(X_train, y_train)]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d202d34d",
   "metadata": {},
   "source": [
    "Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410628e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = UCIClassificationDatasets(train=False,valid=True, data_set=uci_dataset, split_train_size=train_size, double=False, root=root_dir)\n",
    "X_val, y_val = ds_val.data.to(device), ds_val.targets.to(device).unsqueeze(1)\n",
    "val_loader = [(X_val, y_val)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f517c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPS(X_train.shape[1], [width]*depth, 1, activation='tanh', flatten=False).to(device)\n",
    "optim = Adam(model.parameters(), lr=lr)\n",
    "losses = list()\n",
    "for i in range(n_epochs):\n",
    "    f = model(X_train)\n",
    "    w = parameters_to_vector(model.parameters())\n",
    "    reg = 0.5 * prior_prec * w @ w\n",
    "    loss = - lh.log_likelihood(y_train, f) + reg\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    losses.append(loss.item())\n",
    "    model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8bb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap = Laplace(model, float(prior_prec), lh)\n",
    "\n",
    "\n",
    "def get_pred_for(x, model_type='glm', cov_type='full'):\n",
    "    #### INFERENCE (Posterior approximation) ####\n",
    "    lap.infer(train_loader, cov_type=cov_type, dampen_kron=model_type=='bnn')\n",
    "    if model_type == 'glm':\n",
    "        #### GLM PREDICTIVE ####\n",
    "        mu, var = lap.predictive_samples_glm(x, n_samples=n_samples)\n",
    "    elif model_type == 'bnn':\n",
    "        #### BNN PREDICTIVE ####\n",
    "        samples = lap.predictive_samples_bnn(x, n_samples=n_samples)\n",
    "        mu = samples.mean(axis=0)\n",
    "        var = samples.cov(axis=0)\n",
    "    else:\n",
    "        raise ValueError('unsupported model_type.')\n",
    "    mu = mu.detach().cpu().squeeze()\n",
    "    var = var.detach().cpu().squeeze()\n",
    "    return mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtype)\n",
    "print(X_val.dtype)\n",
    "print(mu.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bae456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLM\n",
    "\n",
    "mu_glm, var_glm = get_pred_for(X_val, 'glm', 'full')# runs\n",
    "# mu_glm_kron, var_glm_kron = get_pred_for(X_val, 'glm', 'kron') # doesn't run\n",
    "#mu, var = get_pred_for(X_val, 'glm', 'diag')# doesn't run\n",
    "\n",
    "# BNN\n",
    "mu_bnn, var_bnn = get_pred_for(X_val, 'bnn', 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adcae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_glm = Normal(mu_glm, var_glm)\n",
    "print(-torch.mean(lh_glm.log_prob(y_val.squeeze(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lh_bnn = Normal(mu_bnn, var_bnn)\n",
    "print(-torch.mean(lh_bnn.log_prob(y_val.squeeze(-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601765b1",
   "metadata": {},
   "source": [
    "<h2>Run the classification pipeline for chosen dataset </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc6093",
   "metadata": {},
   "source": [
    "The classification.py script tests 10 options for the prior precision, with a fixed train/val/test split. The results reported in the paper are over 10 different train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d088e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['australian', 'breast_cancer', 'digits', 'glass',\n",
    "            'ionosphere', 'satellite', 'vehicle', 'waveform']\n",
    "seeds = [711, 1, 75, 359, 17, 420, 129, 666, 69, 36]\n",
    "dataset = 'breast_cancer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760da084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to ../experiments/results\n",
      "Reading data from ../data\n",
      "100%|██████████████████████████████████████████| 10/10 [42:12<00:00, 253.22s/it]\n",
      "Writing results to ../experiments/results\n",
      "Reading data from ../data\n",
      "100%|██████████████████████████████████████████| 10/10 [53:43<00:00, 322.32s/it]\n",
      "Writing results to ../experiments/results\n",
      "Reading data from ../data\n",
      "100%|██████████████████████████████████████████| 10/10 [44:43<00:00, 268.37s/it]\n",
      "Writing results to ../experiments/results\n",
      "Reading data from ../data\n",
      " 60%|█████████████████████████▊                 | 6/10 [24:45<16:41, 250.35s/it]"
     ]
    }
   ],
   "source": [
    "for seed in seeds:\n",
    "    if dataset in ['satellite', 'digits']:\n",
    "        logmin = -1.0\n",
    "    else:\n",
    "        logmin = -2.0\n",
    "    !python3 ../experiments/classification.py -d {dataset} --root_dir ../ --seed {seed} --n_layers 2 --activation tanh --name tanh_2 --logd_min {logmin}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320234e",
   "metadata": {},
   "source": [
    "The experiment in experiments/uci_classification_commands.py could otherwise be used, but it does not take into account the different hyperparameter settings required for satellite & digits datasets (different range for prior precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab25be1a",
   "metadata": {},
   "source": [
    "<h2> Manual reading of the result pickle</h2>\n",
    "Read the result pickle (for a single experiment with various prior precisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5fd793",
   "metadata": {},
   "source": [
    "Find  which prior precision gives the best validation NLL for the dataset (based on average NLL performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bdd6af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_best(result_list, model_name='svgp_ntk'):\n",
    "    valid_nlls = np.zeros((len(result_list), len(result_list[0]['deltas'])))\n",
    "    for i, results in enumerate(result_list):\n",
    "        for j, res in enumerate(results['results']):\n",
    "            if f'valid_nll_{model_name}' not in res:\n",
    "                continue\n",
    "            valid_nlls[i, j] = res[f'valid_nll_{model_name}']\n",
    "    mean_nlls = np.mean(valid_nlls, axis=0)\n",
    "    min_nll = mean_nlls.min()\n",
    "    min_index = list(mean_nlls).index(min_nll)\n",
    "    return min_index\n",
    "\n",
    "def get_result_list(dataset,folder_name,  name, seeds):   \n",
    "    result_list = []\n",
    "    for seed in seeds:\n",
    "        file_name = f'../experiments/results/uci/{folder_name}/classification_{dataset}_{name}_{seed}.pkl'\n",
    "        if os.path.isfile(file_name):\n",
    "            with open(file_name, 'rb') as handle:\n",
    "                result_list.append(pickle.load(handle))\n",
    "        else:\n",
    "            print(f'WARNING: No results for seed {seed}, dataset {dataset}')\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b80928",
   "metadata": {},
   "source": [
    "Check the test set performance of the selected prior precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e5bbaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_mean_std(result_list, min_idx, name='svgp_ntk'):\n",
    "    test_nlls = np.zeros(len(result_list))\n",
    "    for i, results in enumerate(result_list):\n",
    "        test_nlls[i] = results['results'][min_idx][f'test_nll_{name}']\n",
    "    mean = np.mean(test_nlls)\n",
    "    std = np.std(test_nlls)\n",
    "    return (mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b87f3",
   "metadata": {},
   "source": [
    "<h2>Automatic table creation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "624634ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_map = {\n",
    "    'NN MAP':  [(0.31, 0.01), (0.11, 0.02), (0.35, 0.02), (0.95,0.03), (0.420, 0.007), (0.335, 0.004), (0.094, 0.003), (0.230, 0.002)],\n",
    "'MFVI': [(0.34, 0.01), (0.11, 0.01), (0.41, 0.01), (1.06,0.01), (0.504, 0.006), (0.393, 0.003), (0.219, 0.004), (0.307, 0.002)],\n",
    "'BNN' : [(0.42, 0.00), (0.19, 0.00), (0.50, 0.00), (1.41,0.00), (0.885, 0.002), (0.516, 0.002), (0.875, 0.002), (0.482, 0.001)],\n",
    "'GLM' : [(0.32, 0.02), (0.10, 0.01), (0.29, 0.01), (0.86,0.01), (0.428, 0.005), (0.339, 0.004), (0.250, 0.002), (0.241, 0.001)],\n",
    "'GLM diag' : [(0.33, 0.01), (0.11, 0.01), (0.35, 0.01), (0.99,0.01), (0.618, 0.003), (0.388, 0.003), (0.409, 0.002), (0.327, 0.002)],\n",
    "'GLM refine' :[(0.32, 0.02), (0.11, 0.01), (0.35, 0.05), (0.98,0.07), (0.402, 0.007), (0.335, 0.004), (0.150, 0.002), (0.227, 0.002)],\n",
    "'GLM refine d' : [(0.31, 0.01), (0.12, 0.02), (0.32, 0.03), (0.83,0.02), (0.432, 0.005), (0.364, 0.008), (0.149, 0.008), (0.248, 0.002)],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "22123466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'valid_nll_svgp_ntk' in result_list[5]['results'][4].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "4ecc81ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering results for 16\n",
      "Gathering results for 32\n",
      "Gathering results for 64\n",
      "Gathering results for 128\n",
      "WARNING: No results for seed 75, dataset breast_cancer\n",
      "WARNING: No results for seed 359, dataset breast_cancer\n",
      "WARNING: No results for seed 17, dataset breast_cancer\n",
      "WARNING: No results for seed 666, dataset breast_cancer\n",
      "WARNING: N seeds for breast_cancer:\n",
      "6\n",
      "WARNING: No results for seed 75, dataset breast_cancer\n",
      "WARNING: No results for seed 359, dataset breast_cancer\n",
      "WARNING: No results for seed 17, dataset breast_cancer\n",
      "WARNING: No results for seed 666, dataset breast_cancer\n",
      "WARNING: N seeds for breast_cancer:\n",
      "6\n",
      "Gathering results for 256\n",
      "WARNING: No results for seed 711, dataset breast_cancer\n",
      "WARNING: No results for seed 1, dataset breast_cancer\n",
      "WARNING: No results for seed 75, dataset breast_cancer\n",
      "WARNING: No results for seed 359, dataset breast_cancer\n",
      "WARNING: No results for seed 17, dataset breast_cancer\n",
      "WARNING: No results for seed 420, dataset breast_cancer\n",
      "WARNING: No results for seed 129, dataset breast_cancer\n",
      "WARNING: No results for seed 666, dataset breast_cancer\n",
      "WARNING: No results for seed 69, dataset breast_cancer\n",
      "WARNING: No results for seed 36, dataset breast_cancer\n",
      "WARNING: N seeds for breast_cancer:\n",
      "0\n",
      "WARNING: No results for seed 711, dataset breast_cancer\n",
      "WARNING: No results for seed 1, dataset breast_cancer\n",
      "WARNING: No results for seed 75, dataset breast_cancer\n",
      "WARNING: No results for seed 359, dataset breast_cancer\n",
      "WARNING: No results for seed 17, dataset breast_cancer\n",
      "WARNING: No results for seed 420, dataset breast_cancer\n",
      "WARNING: No results for seed 129, dataset breast_cancer\n",
      "WARNING: No results for seed 666, dataset breast_cancer\n",
      "WARNING: No results for seed 69, dataset breast_cancer\n",
      "WARNING: No results for seed 36, dataset breast_cancer\n",
      "WARNING: N seeds for breast_cancer:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inducing_points = [16, 32, 64, 128, 256]# [16, 32, 64, 128]\n",
    "folder_name = '09'\n",
    "pretty_names = {'sparse_16_svgp_ntk': 'SVGP (16)',\n",
    "                'sparse_32_svgp_ntk': 'SVGP (32)',\n",
    "                'sparse_64_svgp_ntk': 'SVGP (64)',\n",
    "                'sparse_128_svgp_ntk': 'SVGP (128)',\n",
    "                'sparse_256_svgp_ntk': 'SVGP (256)',\n",
    "               'sparse_16_gp_subset': 'GP subset(16)',\n",
    "               'sparse_32_gp_subset': 'GP subset(32)',\n",
    "               'sparse_64_gp_subset': 'GP subset(64)',\n",
    "               'sparse_128_gp_subset': 'GP subset(128)',          \n",
    "               'sparse_256_gp_subset': 'GP subset(256)'}\n",
    "method_names = ['svgp_ntk', 'gp_subset']\n",
    "datasets = ['australian', 'breast_cancer', 'ionosphere','glass',\n",
    "            'vehicle','waveform', 'digits', 'satellite']\n",
    "data_names = ['australian', 'cancer', 'ionosphere', 'glass', 'vehicle', 'waveform', 'digits', 'satellite']\n",
    "seeds = [711, 1, 75, 359, 17, 420, 129, 666, 69, 36]\n",
    "for n_inducing in inducing_points:\n",
    "    print(f'Gathering results for {n_inducing}')\n",
    "    exp_name = f'sparse_{n_inducing}'\n",
    "    for method_name in method_names:\n",
    "        table_list = []\n",
    "        for dataset in datasets:\n",
    "            result_list = get_result_list(dataset, folder_name, exp_name, seeds)\n",
    "            if len(result_list) < 10:\n",
    "                print(f'WARNING: N seeds for {dataset}:')\n",
    "                print(len(result_list))\n",
    "                table_list.append((0, 0))\n",
    "                continue\n",
    "            min_idx = get_val_best(result_list, method_name)\n",
    "            (mean, std) = get_test_mean_std(result_list, min_idx, name=method_name)\n",
    "            table_list.append((round(mean, 3), round(std, 3)))\n",
    "        method_map[pretty_names[f'sparse_{n_inducing}_{method_name}']] = table_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "651a362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN MAP': [(0.31, 0.01),\n",
       "  (0.11, 0.02),\n",
       "  (0.35, 0.02),\n",
       "  (0.95, 0.03),\n",
       "  (0.42, 0.007),\n",
       "  (0.335, 0.004),\n",
       "  (0.094, 0.003),\n",
       "  (0.23, 0.002)],\n",
       " 'MFVI': [(0.34, 0.01),\n",
       "  (0.11, 0.01),\n",
       "  (0.41, 0.01),\n",
       "  (1.06, 0.01),\n",
       "  (0.504, 0.006),\n",
       "  (0.393, 0.003),\n",
       "  (0.219, 0.004),\n",
       "  (0.307, 0.002)],\n",
       " 'BNN': [(0.42, 0.0),\n",
       "  (0.19, 0.0),\n",
       "  (0.5, 0.0),\n",
       "  (1.41, 0.0),\n",
       "  (0.885, 0.002),\n",
       "  (0.516, 0.002),\n",
       "  (0.875, 0.002),\n",
       "  (0.482, 0.001)],\n",
       " 'GLM': [(0.32, 0.02),\n",
       "  (0.1, 0.01),\n",
       "  (0.29, 0.01),\n",
       "  (0.86, 0.01),\n",
       "  (0.428, 0.005),\n",
       "  (0.339, 0.004),\n",
       "  (0.25, 0.002),\n",
       "  (0.241, 0.001)],\n",
       " 'GLM diag': [(0.33, 0.01),\n",
       "  (0.11, 0.01),\n",
       "  (0.35, 0.01),\n",
       "  (0.99, 0.01),\n",
       "  (0.618, 0.003),\n",
       "  (0.388, 0.003),\n",
       "  (0.409, 0.002),\n",
       "  (0.327, 0.002)],\n",
       " 'GLM refine': [(0.32, 0.02),\n",
       "  (0.11, 0.01),\n",
       "  (0.35, 0.05),\n",
       "  (0.98, 0.07),\n",
       "  (0.402, 0.007),\n",
       "  (0.335, 0.004),\n",
       "  (0.15, 0.002),\n",
       "  (0.227, 0.002)],\n",
       " 'GLM refine d': [(0.31, 0.01),\n",
       "  (0.12, 0.02),\n",
       "  (0.32, 0.03),\n",
       "  (0.83, 0.02),\n",
       "  (0.432, 0.005),\n",
       "  (0.364, 0.008),\n",
       "  (0.149, 0.008),\n",
       "  (0.248, 0.002)],\n",
       " 'SVGP (16)': [(0.322, 0.028),\n",
       "  (0.102, 0.034),\n",
       "  (0.333, 0.041),\n",
       "  (0.982, 0.072),\n",
       "  (0.545, 0.023),\n",
       "  (0.352, 0.024),\n",
       "  (0.458, 0.017),\n",
       "  (0.366, 0.014)],\n",
       " 'GP subset(16)': [(0.467, 0.02),\n",
       "  (0.268, 0.012),\n",
       "  (0.486, 0.02),\n",
       "  (1.225, 0.047),\n",
       "  (1.001, 0.024),\n",
       "  (0.651, 0.009),\n",
       "  (1.724, 0.049),\n",
       "  (1.111, 0.026)],\n",
       " 'SVGP (32)': [(0.316, 0.031),\n",
       "  (0.103, 0.036),\n",
       "  (0.313, 0.046),\n",
       "  (0.886, 0.082),\n",
       "  (0.51, 0.021),\n",
       "  (0.343, 0.025),\n",
       "  (0.375, 0.015),\n",
       "  (0.32, 0.013)],\n",
       " 'GP subset(32)': [(0.406, 0.016),\n",
       "  (0.206, 0.017),\n",
       "  (0.434, 0.025),\n",
       "  (1.086, 0.073),\n",
       "  (0.848, 0.027),\n",
       "  (0.535, 0.017),\n",
       "  (1.394, 0.01),\n",
       "  (0.827, 0.016)],\n",
       " 'SVGP (64)': [(0.316, 0.03),\n",
       "  (0.102, 0.036),\n",
       "  (0.306, 0.048),\n",
       "  (0.867, 0.088),\n",
       "  (0.478, 0.03),\n",
       "  (0.339, 0.027),\n",
       "  (0.338, 0.018),\n",
       "  (0.292, 0.013)],\n",
       " 'GP subset(64)': [(0.369, 0.018),\n",
       "  (0.163, 0.02),\n",
       "  (0.396, 0.032),\n",
       "  (1.007, 0.077),\n",
       "  (0.669, 0.015),\n",
       "  (0.457, 0.017),\n",
       "  (1.088, 0.021),\n",
       "  (0.632, 0.015)],\n",
       " 'SVGP (128)': [(0.316, 0.03),\n",
       "  (0, 0),\n",
       "  (0.306, 0.049),\n",
       "  (0.863, 0.091),\n",
       "  (0.444, 0.032),\n",
       "  (0.339, 0.027),\n",
       "  (0.316, 0.018),\n",
       "  (0.281, 0.013)],\n",
       " 'GP subset(128)': [(0.339, 0.025),\n",
       "  (0, 0),\n",
       "  (0.341, 0.04),\n",
       "  (0.891, 0.087),\n",
       "  (0.578, 0.017),\n",
       "  (0.392, 0.022),\n",
       "  (0.801, 0.019),\n",
       "  (0.514, 0.009)],\n",
       " 'SVGP (256)': [(0.316, 0.03),\n",
       "  (0, 0),\n",
       "  (0.306, 0.049),\n",
       "  (0.861, 0.091),\n",
       "  (0.441, 0.034),\n",
       "  (0.339, 0.027),\n",
       "  (0.299, 0.018),\n",
       "  (0.272, 0.012)],\n",
       " 'GP subset(256)': [(0.322, 0.029),\n",
       "  (0, 0),\n",
       "  (0.306, 0.048),\n",
       "  (0.863, 0.093),\n",
       "  (0.53, 0.018),\n",
       "  (0.355, 0.023),\n",
       "  (0.608, 0.017),\n",
       "  (0.426, 0.012)]}"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f19ba35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to paper: ['NN MAP', 'MFVI', 'BNN', 'GLM', 'GLM diag', 'GLM refine', 'GLM refine d', 'GP subset(256)', 'SVGP (256)']\n",
      "Writing to appendix: ['SVGP (16)', 'GP subset(16)', 'SVGP (32)', 'GP subset(32)', 'SVGP (64)', 'GP subset(64)', 'SVGP (128)', 'GP subset(128)']\n",
      "['\\\\begin{tabular}{l C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw}}', '\\\\toprule', '& NN MAP & MFVI & BNN & GLM & GLM diag & GLM refine & GLM refine d & GP subset(256) & SVGP (256)  \\\\\\\\', '\\\\midrule', '\\\\sc australian & \\\\val{0.31}{0.01} & \\\\val{0.34}{0.01} & \\\\val{0.42}{0.0} & \\\\val{0.32}{0.02} & \\\\val{0.33}{0.01} & \\\\val{0.32}{0.02} & \\\\val{0.31}{0.01} & \\\\val{0.322}{0.029} & \\\\val{0.316}{0.03} \\\\\\\\', '\\\\sc cancer & \\\\val{0.11}{0.02} & \\\\val{0.11}{0.01} & \\\\val{0.19}{0.0} & \\\\val{0.1}{0.01} & \\\\val{0.11}{0.01} & \\\\val{0.11}{0.01} & \\\\val{0.12}{0.02} & \\\\val{0}{0} & \\\\val{0}{0} \\\\\\\\', '\\\\sc ionosphere & \\\\val{0.35}{0.02} & \\\\val{0.41}{0.01} & \\\\val{0.5}{0.0} & \\\\val{0.29}{0.01} & \\\\val{0.35}{0.01} & \\\\val{0.35}{0.05} & \\\\val{0.32}{0.03} & \\\\val{0.306}{0.048} & \\\\val{0.306}{0.049} \\\\\\\\', '\\\\sc glass & \\\\val{0.95}{0.03} & \\\\val{1.06}{0.01} & \\\\val{1.41}{0.0} & \\\\val{0.86}{0.01} & \\\\val{0.99}{0.01} & \\\\val{0.98}{0.07} & \\\\val{0.83}{0.02} & \\\\val{0.863}{0.093} & \\\\val{0.861}{0.091} \\\\\\\\', '\\\\sc vehicle & \\\\val{0.42}{0.007} & \\\\val{0.504}{0.006} & \\\\val{0.885}{0.002} & \\\\val{0.428}{0.005} & \\\\val{0.618}{0.003} & \\\\val{0.402}{0.007} & \\\\val{0.432}{0.005} & \\\\val{0.53}{0.018} & \\\\val{0.441}{0.034} \\\\\\\\', '\\\\sc waveform & \\\\val{0.335}{0.004} & \\\\val{0.393}{0.003} & \\\\val{0.516}{0.002} & \\\\val{0.339}{0.004} & \\\\val{0.388}{0.003} & \\\\val{0.335}{0.004} & \\\\val{0.364}{0.008} & \\\\val{0.355}{0.023} & \\\\val{0.339}{0.027} \\\\\\\\', '\\\\sc digits & \\\\val{0.094}{0.003} & \\\\val{0.219}{0.004} & \\\\val{0.875}{0.002} & \\\\val{0.25}{0.002} & \\\\val{0.409}{0.002} & \\\\val{0.15}{0.002} & \\\\val{0.149}{0.008} & \\\\val{0.608}{0.017} & \\\\val{0.299}{0.018} \\\\\\\\', '\\\\sc satellite & \\\\val{0.23}{0.002} & \\\\val{0.307}{0.002} & \\\\val{0.482}{0.001} & \\\\val{0.241}{0.001} & \\\\val{0.327}{0.002} & \\\\val{0.227}{0.002} & \\\\val{0.248}{0.002} & \\\\val{0.426}{0.012} & \\\\val{0.272}{0.012} \\\\\\\\', '\\\\bottomrule', '\\\\end{tabular}']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "paper_methods = ['NN MAP', 'MFVI', 'BNN', 'GLM', 'GLM diag', 'GLM refine', 'GLM refine d', 'GP subset(256)', 'SVGP (256)']\n",
    "all_methods = list(method_map.keys())\n",
    "appendix_methods = []\n",
    "for method in all_methods:\n",
    "    if method not in paper_methods:\n",
    "        appendix_methods.append(method)\n",
    "print(f'Writing to paper: {paper_methods}')\n",
    "print(f'Writing to appendix: {appendix_methods}')\n",
    "\n",
    "lines = []\n",
    "lines.append(r'\\begin{tabular}{l C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw}}')\n",
    "lines.append(r'\\toprule')\n",
    "header_str = ''\n",
    "for method_name in paper_methods:\n",
    "    header_str += f'& {method_name} '\n",
    "header_str += r' \\\\'\n",
    "lines.append(header_str)\n",
    "lines.append(r'\\midrule')\n",
    "for i, data_name in enumerate(data_names):\n",
    "    line_str = f'\\sc {data_name} &'\n",
    "    for method_name in paper_methods:\n",
    "        (mean, var) = method_map[method_name][i]\n",
    "        mean_var = f'{mean} {var}'\n",
    "        line_str += r' \\val{'\n",
    "        line_str += str(mean)\n",
    "        line_str += '}{'\n",
    "        line_str += str(var)\n",
    "        line_str += '} &'\n",
    "    line_str = line_str[:-2]\n",
    "    line_str += r' \\\\'\n",
    "    lines.append(line_str)\n",
    "lines.append(r'\\bottomrule')\n",
    "lines.append(r'\\end{tabular}')\n",
    "tex_file = 'uci.tex'\n",
    "os.remove(tex_file)\n",
    "with open(tex_file, 'a') as file:\n",
    "    for line in lines:\n",
    "        file.write(line+'\\n')\n",
    "    \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "47b0c68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\begin{tabular}{l C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw}}', '\\\\toprule', '& SVGP (16) & GP subset(16) & SVGP (32) & GP subset(32) & SVGP (64) & GP subset(64) & SVGP (128) & GP subset(128)  \\\\\\\\', '\\\\midrule', '\\\\sc australian & \\\\val{0.322}{0.028} & \\\\val{0.467}{0.02} & \\\\val{0.316}{0.031} & \\\\val{0.406}{0.016} & \\\\val{0.316}{0.03} & \\\\val{0.369}{0.018} & \\\\val{0.316}{0.03} & \\\\val{0.339}{0.025} \\\\\\\\', '\\\\sc cancer & \\\\val{0.102}{0.034} & \\\\val{0.268}{0.012} & \\\\val{0.103}{0.036} & \\\\val{0.206}{0.017} & \\\\val{0.102}{0.036} & \\\\val{0.163}{0.02} & \\\\val{0}{0} & \\\\val{0}{0} \\\\\\\\', '\\\\sc ionosphere & \\\\val{0.333}{0.041} & \\\\val{0.486}{0.02} & \\\\val{0.313}{0.046} & \\\\val{0.434}{0.025} & \\\\val{0.306}{0.048} & \\\\val{0.396}{0.032} & \\\\val{0.306}{0.049} & \\\\val{0.341}{0.04} \\\\\\\\', '\\\\sc glass & \\\\val{0.982}{0.072} & \\\\val{1.225}{0.047} & \\\\val{0.886}{0.082} & \\\\val{1.086}{0.073} & \\\\val{0.867}{0.088} & \\\\val{1.007}{0.077} & \\\\val{0.863}{0.091} & \\\\val{0.891}{0.087} \\\\\\\\', '\\\\sc vehicle & \\\\val{0.545}{0.023} & \\\\val{1.001}{0.024} & \\\\val{0.51}{0.021} & \\\\val{0.848}{0.027} & \\\\val{0.478}{0.03} & \\\\val{0.669}{0.015} & \\\\val{0.444}{0.032} & \\\\val{0.578}{0.017} \\\\\\\\', '\\\\sc waveform & \\\\val{0.352}{0.024} & \\\\val{0.651}{0.009} & \\\\val{0.343}{0.025} & \\\\val{0.535}{0.017} & \\\\val{0.339}{0.027} & \\\\val{0.457}{0.017} & \\\\val{0.339}{0.027} & \\\\val{0.392}{0.022} \\\\\\\\', '\\\\sc digits & \\\\val{0.458}{0.017} & \\\\val{1.724}{0.049} & \\\\val{0.375}{0.015} & \\\\val{1.394}{0.01} & \\\\val{0.338}{0.018} & \\\\val{1.088}{0.021} & \\\\val{0.316}{0.018} & \\\\val{0.801}{0.019} \\\\\\\\', '\\\\sc satellite & \\\\val{0.366}{0.014} & \\\\val{1.111}{0.026} & \\\\val{0.32}{0.013} & \\\\val{0.827}{0.016} & \\\\val{0.292}{0.013} & \\\\val{0.632}{0.015} & \\\\val{0.281}{0.013} & \\\\val{0.514}{0.009} \\\\\\\\', '\\\\bottomrule', '\\\\end{tabular}']\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "lines.append(r'\\begin{tabular}{l C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw}}')\n",
    "lines.append(r'\\toprule')\n",
    "header_str = ''\n",
    "for method_name in appendix_methods:\n",
    "    header_str += f'& {method_name} '\n",
    "header_str += r' \\\\'\n",
    "lines.append(header_str)\n",
    "lines.append(r'\\midrule')\n",
    "for i, data_name in enumerate(data_names):\n",
    "    line_str = f'\\sc {data_name} &'\n",
    "    for method_name in appendix_methods:\n",
    "        (mean, var) = method_map[method_name][i]\n",
    "        mean_var = f'{mean} {var}'\n",
    "        line_str += r' \\val{'\n",
    "        line_str += str(mean)\n",
    "        line_str += '}{'\n",
    "        line_str += str(var)\n",
    "        line_str += '} &'\n",
    "    line_str = line_str[:-2]\n",
    "    line_str += r' \\\\'\n",
    "    lines.append(line_str)\n",
    "lines.append(r'\\bottomrule')\n",
    "lines.append(r'\\end{tabular}')\n",
    "tex_file = 'uci_all.tex'\n",
    "os.remove(tex_file)\n",
    "with open(tex_file, 'a') as file:\n",
    "    for line in lines:\n",
    "        file.write(line+'\\n')\n",
    "    \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9064636a",
   "metadata": {},
   "source": [
    "<h2>Create img result table </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9c8c851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_best_img(result_list, deltas, model_name='svgp_ntk'):\n",
    "    print(model_name)\n",
    "    valid_nlls = np.zeros((len(result_list), len(deltas)))\n",
    "    for i, results in enumerate(result_list):\n",
    "        for j, delta in enumerate(deltas):\n",
    "            valid_res = results[delta]['nll_va']\n",
    "            valid_nlls[i, j] = valid_res\n",
    "    mean_nlls = np.mean(valid_nlls, axis=0)\n",
    "    print(mean_nlls)\n",
    "    min_nll = mean_nlls.min()\n",
    "    min_index = list(mean_nlls).index(min_nll)\n",
    "    return min_index\n",
    "\n",
    "def get_result_list_img(dataset, seeds, name='sparse_1000', model='MLP'):   \n",
    "    result_list = []\n",
    "    deltas = []\n",
    "    dir_name = f'../experiments/results/{dataset}/models/'\n",
    "    for seed in seeds:\n",
    "        seed_res = dict()\n",
    "        for file in os.listdir(dir_name):\n",
    "            ds, m, s, delta = file[:-3].split('_')\n",
    "            if m != model:\n",
    "                continue\n",
    "            if s != seed:\n",
    "                continue\n",
    "            state = torch.load(file)\n",
    "            if f'svgp_ntk_{name}' not in state:\n",
    "                continue\n",
    "            seed_res[delta] = state[f'svgp_ntk_{name}']\n",
    "            deltas.append(delta)\n",
    "        if len(seed_res) > 0:\n",
    "            result_list.append(seed_res)\n",
    "    deltas = list(set(deltas))\n",
    "    print(f'N seeds: {len(result_list)}')\n",
    "    return result_list, deltas\n",
    "                          \n",
    "def get_test_mean_std_img(result_list, deltas, min_idx):\n",
    "    test_nlls = np.zeros(len(result_list))\n",
    "    min_delta = deltas[min_idx]\n",
    "    for i, results in enumerate(result_list):\n",
    "        test_nlls[i] = results[min_delta]['nll_te']\n",
    "    mean = np.mean(test_nlls)\n",
    "    std = np.std(test_nlls)\n",
    "    return (mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d24ee099",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_map_img = {\n",
    "    'MAP': {'nll': [(0.258, 0.004), (0.605, 0.007)] , 'ece': [(0.017, 0.001), (0.066, 0.004)], 'acc':[(91.39, 0.11), (80.92, 0.32)], 'ood-auc': [(0.864, 0.014), (0.792, 0.008)]} ,\n",
    "'BNN predictive': {'nll': [(0.942, 0.016), (2.114, 0.021)] , 'ece': [(0.411, 0.008), (0.095, 0.012)], 'acc':[(84.42, 0.12), (21.74, 0.80)], 'ood-auc': [(0.945, 0.002), (0.689, 0.020)]} ,\n",
    "'BNN predictive (Ritter et al.)' : {'nll': [(0.265, 0.004), (0.588, 0.005)] , 'ece': [(0.024, 0.002), (0.052, 0.005)], 'acc':[(91.20, 0.07), (80.78, 0.36)], 'ood-auc': [(0.947, 0.006), (0.783, 0.007)]}  ,\n",
    "'GLM predictive' :{'nll': [(0.244, 0.003), (0.601, 0.008)] , 'ece': [(0.012, 0.003), (0.084, 0.010)], 'acc':[(92.25, 0.10), (81.37, 0.15)], 'ood-auc': [(0.955, 0.006), (0.843, 0.016)]}  ,\n",
    "'GP predictive' : {'nll': [(0.250, 0.004), (0.555, 0.008)] , 'ece': [(0.007, 0.001), (0.017, 0.003)], 'acc':[(91.36, 0.11), (81.01, 0.32)], 'ood-auc': [(0.918, 0.010), (0.820, 0.013)]} ,\n",
    "'SVGP predictive' : {'nll': [(0, 0), (0.0, 0.00)] , 'ece': [(0.00, 0.000), (0.00, 0.000)], 'acc':[(0.00, 0.00), (0.00, 0.00)], 'ood-auc': [(0.00, 0.00), (0.00, 0.00)]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d47cdeb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[267], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnll\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mece\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mood-auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m seeds \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m117\u001b[39m, \u001b[38;5;241m68\u001b[39m, \u001b[38;5;241m187\u001b[39m, \u001b[38;5;241m27\u001b[39m, \u001b[38;5;241m51\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp_name \u001b[38;5;129;01min\u001b[39;00m exper_names:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m method_name \u001b[38;5;129;01min\u001b[39;00m method_names:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exper_names = ['sparse_1000']\n",
    "pretty_names = {'sparse_1000_svgp_ntk': 'SVGP (1000)'}\n",
    "method_names = ['svgp_ntk']\n",
    "datasets = ['FMNIST', 'CIFAR10']\n",
    "model = 'MLP'\n",
    "data_names = ['FMNIST', 'CIFAR10']\n",
    "metrics = ['acc', 'nll', 'ece', 'ood-auc']\n",
    "seeds = [117, 68, 187, 27, 51]\n",
    "assert 1 == 0\n",
    "for exp_name in exper_names:\n",
    "    for method_name in method_names:\n",
    "        table_list = []\n",
    "        print(method_name)\n",
    "        for dataset in datasets:\n",
    "            print(dataset)\n",
    "            result_list, deltas = get_result_list_img(dataset,  seeds, name=exper_name,  model=model)\n",
    "            print('N seeds:')\n",
    "            print(len(result_list))\n",
    "            if len(result_list) == 0:\n",
    "                table_list.append((0, 0))\n",
    "                continue\n",
    "            min_idx = get_val_best_img(result_list, deltas)\n",
    "            (mean, std) = get_test_mean_std_img(result_list, min_idx, name=method_name)\n",
    "            table_list.append((round(mean, 3), round(std, 3)))\n",
    "        method_map_img[pretty_names[exp_name+'_'+method_name]] = table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0e24951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\begin{tabular}{l C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw} C{0.6\\\\tblw}  C{0.6\\\\tblw}}', '\\\\toprule', '& acc & nll & ece & ood-auc  \\\\\\\\', '\\\\midrule', '\\\\sc FMNIST and MAP & \\\\val{91.39}{0.11} & \\\\val{0.258}{0.004} & \\\\val{0.017}{0.001} & \\\\val{0.864}{0.014} \\\\\\\\', '\\\\sc FMNIST and BNN predictive & \\\\val{84.42}{0.12} & \\\\val{0.942}{0.016} & \\\\val{0.411}{0.008} & \\\\val{0.945}{0.002} \\\\\\\\', '\\\\sc FMNIST and BNN predictive (Ritter et al.) & \\\\val{91.2}{0.07} & \\\\val{0.265}{0.004} & \\\\val{0.024}{0.002} & \\\\val{0.947}{0.006} \\\\\\\\', '\\\\sc FMNIST and GLM predictive & \\\\val{92.25}{0.1} & \\\\val{0.244}{0.003} & \\\\val{0.012}{0.003} & \\\\val{0.955}{0.006} \\\\\\\\', '\\\\sc FMNIST and GP predictive & \\\\val{91.36}{0.11} & \\\\val{0.25}{0.004} & \\\\val{0.007}{0.001} & \\\\val{0.918}{0.01} \\\\\\\\', '\\\\sc FMNIST and SVGP predictive & \\\\val{0.0}{0.0} & \\\\val{0}{0} & \\\\val{0.0}{0.0} & \\\\val{0.0}{0.0} \\\\\\\\', '\\\\sc CIFAR10 and MAP & \\\\val{80.92}{0.32} & \\\\val{0.605}{0.007} & \\\\val{0.066}{0.004} & \\\\val{0.792}{0.008} \\\\\\\\', '\\\\sc CIFAR10 and BNN predictive & \\\\val{21.74}{0.8} & \\\\val{2.114}{0.021} & \\\\val{0.095}{0.012} & \\\\val{0.689}{0.02} \\\\\\\\', '\\\\sc CIFAR10 and BNN predictive (Ritter et al.) & \\\\val{80.78}{0.36} & \\\\val{0.588}{0.005} & \\\\val{0.052}{0.005} & \\\\val{0.783}{0.007} \\\\\\\\', '\\\\sc CIFAR10 and GLM predictive & \\\\val{81.37}{0.15} & \\\\val{0.601}{0.008} & \\\\val{0.084}{0.01} & \\\\val{0.843}{0.016} \\\\\\\\', '\\\\sc CIFAR10 and GP predictive & \\\\val{81.01}{0.32} & \\\\val{0.555}{0.008} & \\\\val{0.017}{0.003} & \\\\val{0.82}{0.013} \\\\\\\\', '\\\\sc CIFAR10 and SVGP predictive & \\\\val{0.0}{0.0} & \\\\val{0.0}{0.0} & \\\\val{0.0}{0.0} & \\\\val{0.0}{0.0} \\\\\\\\', '\\\\bottomrule', '\\\\end{tabular}']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "lines = []\n",
    "lines.append(r'\\begin{tabular}{l C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw} C{0.6\\tblw}  C{0.6\\tblw}}')\n",
    "lines.append(r'\\toprule')\n",
    "header_str = ''\n",
    "for metric in metrics:\n",
    "    header_str += f'& {metric} '\n",
    "header_str += r' \\\\'\n",
    "lines.append(header_str)\n",
    "lines.append(r'\\midrule')\n",
    "for i, dataset in enumerate(datasets):\n",
    "    for method_name in method_map_img:\n",
    "        line_str = f'\\sc {dataset} and {method_name} &'\n",
    "        for metric in metrics:\n",
    "            (mean, var) = method_map_img[method_name][metric][i]\n",
    "            mean_var = f'{mean} {var}'\n",
    "            line_str += r' \\val{'\n",
    "            line_str += str(mean)\n",
    "            line_str += '}{'\n",
    "            line_str += str(var)\n",
    "            line_str += '} &'\n",
    "        line_str = line_str[:-2]\n",
    "        line_str += r' \\\\'\n",
    "        lines.append(line_str)\n",
    "lines.append(r'\\bottomrule')\n",
    "lines.append(r'\\end{tabular}')\n",
    "tex_file = 'img_super.tex'\n",
    "\n",
    "os.remove(tex_file)\n",
    "with open(tex_file, 'a') as file:\n",
    "    for line in lines:\n",
    "        file.write(line+'\\n')\n",
    "    \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cab4f7",
   "metadata": {},
   "source": [
    "<h2>Run Image experiments </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c46c905a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'MNIST'\n",
    "model = 'MLP'\n",
    "seed = 117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a10bcad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to ../experiments/results/MNIST\n",
      "Reading data from ../data\n",
      "Dataset: MNIST\n",
      "Seed: 117\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "9920512it [00:00, 12327924.77it/s]                                              \n",
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "32768it [00:00, 298645.29it/s]\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "1654784it [00:00, 6915425.85it/s]                                               \n",
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "8192it [00:00, 29604.16it/s]                                                    \n",
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "/Users/tamire1/miniconda3/envs/bnn-env-3/lib/python3.7/site-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1595629430416/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "Done!\n",
      "  3%|█▏                                        | 14/500 [01:12<42:17,  5.22s/it]^C\n",
      "  3%|█▏                                        | 14/500 [01:13<42:32,  5.25s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"../experiments/imgclassification.py\", line 164, in <module>\n",
      "    main(ds_train, ds_test, model_name, seed, n_epochs, batch_size, lr, deltas, device, fname, res_dir)\n",
      "  File \"../experiments/imgclassification.py\", line 98, in main\n",
      "    loss.backward()\n",
      "  File \"/Users/tamire1/miniconda3/envs/bnn-env-3/lib/python3.7/site-packages/torch/tensor.py\", line 185, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/Users/tamire1/miniconda3/envs/bnn-env-3/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 ../experiments/imgclassification.py -d {ds} -m {model} -s {seed}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
