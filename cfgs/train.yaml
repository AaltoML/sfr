defaults:
  - train_config
  # Use slurm on cluster or local?
  # - override hydra/launcher: slurm
  - override hydra/launcher: lumi
  - _self_

dataset: "FMNIST"
train_val_split: 0.8
debug: False

prior_precision: 0.0013
num_inducing: 2048
dual_batch_size: 1000
jitter: 1e-4
likelihood_eps: 0.0  # for numerical stability

# Training config
batch_size: 128
lr: 1e-4
n_epochs: 10000
# Early stopping on validation loss
early_stop_patience: 2
early_stop_min_delta: 0.0

# Experiment config
logging_epoch_freq: 2
seed: 42
device: "cuda"  # "cpu" or "cuda" etc

# W&B config
use_wandb: False
wandb_project_name: "sfr"

hydra:
  run:
    dir: output/${hydra.job.name}/${now:%Y-%m-%d_%H-%M-%S}
  job:
    chdir: true
  sweep:
    dir: ${hydra.run.dir}
    subdir: ${hydra.job.num}
  job_logging:
    root:
      level: INFO # DEBUG
