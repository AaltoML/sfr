%!TeX program = lualatex

\documentclass[final,12pt]{beamer}

% ====================
% Packages
% ====================

% Packages
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[size=a1,orientation=portrait,scale=1.4]{beamerposter}
\usetheme{aalto}
\usecolortheme{aalto}
\usepackage{graphicx}
%\usepackage[square]{natbib}
%\setlength{\bibsep}{4pt plus 0.3ex}  % Squeeze line spacing in references
\usepackage{booktabs}
% Tikz
\usepackage{tikz}
\usetikzlibrary{patterns}
\usetikzlibrary{decorations,backgrounds,arrows.meta,calc}
\usetikzlibrary{shapes,arrows,positioning}
\usepackage{pgfplots}
\usepackage{subcaption}
\usetikzlibrary{}
\usepackage{chronosys}
\newcommand{\blue}[1]{\textcolor{aaltoblue}{#1}}
\newcommand{\black}[1]{\textcolor{black}{#1}}
\usepackage{color}

% Array/table packages
\usepackage{tabularx}
\usepackage{array,multirow}
\usepackage{colortbl}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}p{#1}}
\newlength{\tblw}

% Our method
\newcommand{\our}{SFR}
	
% Custom error formatting
%\newcommand{\val}[2]{ $#1$\textcolor{gray}{\tiny ${\pm}#2$}} 

\usepackage{bm}
\newcommand{\mathbold}[1]{\bm{#1}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\renewcommand{\mid}{\,|\,}
	

% ====================
% Lengths
% ====================

% If you have N columns, choose \sepwidth and \colwidth such that
% (N+1)*\sepwidth + N*\colwidth = \paperwidth
\newlength{\sepwidth}
\newlength{\colwidth}
\setlength{\sepwidth}{0.025\paperwidth}
\setlength{\colwidth}{0.45\paperwidth}
\newcommand{\separatorcolumn}{\begin{column}{\sepwidth}\end{column}}

% Math and miscellaneous
\renewcommand{\mid}[0]{\,|\,}


% Config for Arno's awesome TikZ plotting stuff
\newlength{\figurewidth}
\newlength{\figureheight}


% ====================
% Title
% ====================

\title{Sparse Function-space Representation \\ of Neural Networks}

\author{%
  Aidan Scannell\textsuperscript{\star}\,\inst{1}\,\inst{2} \;
  Riccardo Mereu\textsuperscript{\star}\,\inst{1} \;
  Paul Chang\,\inst{1} \\
  Ella Tamir\,\inst{1}\;
  Joni Pajarinen\,\inst{1}\;
  Arno Solin\,\inst{1}
}

%\author{Your Name\inst{1} ~~ Collaborator Name\inst{2} ~~ Arno Solin\inst{1}}

\institute[shortinst]{ \inst{1}Aalto University \qquad \inst{2} Finnish Center for Artificial Intelligence}


% ====================
% Footer (optional)
% ====================

\footercontent{
  International Conference in Machine Learning (ICML 2023) --- Hawaii, US \hfill
  \href{mailto:aidan.scannell@aalto.fi}{aidan.scannell@aalto.fi}}

% ====================
% Body
% ====================

\begin{document}

\begin{frame}[t]
\begin{columns}[t]
\begin{column}{2.05\colwidth}
\begin{alertblock}{TL;DR}
{\bf \alert{TODO: Rewrite}}
  Deep neural networks are known to lack uncertainty estimates, struggle to incorporate new data, and suffer from catastrophic forgetting. We present a method that mitigates these issues by converting neural networks from weight-space to a low-rank function-space representation, via the so-called dual parameters. In contrast to previous work, our sparse representation captures the joint distribution over the entire data set, rather than only over a subset. This offers a compact and principled way of capturing uncertainty and enables us to incorporate new data without retraining whilst retaining predictive performance. We provide proof-of-concept demonstrations with the proposed approach for quantifying uncertainty in supervised learning on UCI benchmark tasks.

%   \begin{itemize}
%     \item We present \alert{our awesome method}, a novel and beautiful approach for something
%     \item Other bullet
%     \item Keep it short
%   \end{itemize}
  \end{alertblock}\end{column}
\end{columns}

\begin{columns}[t]


\separatorcolumn

\begin{column}{\colwidth}
  \begin{minipage}{\textwidth}
  	\begin{figure}[t]
    \pgfplotsset{axis on top,scale only axis,width=\figurewidth,height=\figureheight, ylabel near ticks,ylabel style={yshift=-2pt},y tick label style={rotate=90},legend style={nodes={scale=1., transform shape}},tick label style={font=\tiny,scale=1}}
  \pgfplotsset{xlabel={Input, $x$},axis line style={rounded corners=2pt}}
  % Set figure 
  \setlength{\figurewidth}{.28\textwidth}
  \setlength{\figureheight}{\figurewidth}
  %
  \def\inducing{\large Sparse inducing points}
  %
  \begin{subfigure}[c]{.34\textwidth}
    \raggedleft
    \pgfplotsset{ylabel={Output, $y$}}
    \input{./fig/regression-nn.tex}%
  \end{subfigure}
  \hfill  
  \begin{subfigure}[c]{.01\textwidth}
    \centering
    \tikz[overlay,remember picture]\node(p0){};
  \end{subfigure}  
  \hfill
  \begin{subfigure}[c]{.28\textwidth}
    \raggedleft
    \pgfplotsset{yticklabels={,,},ytick={\empty}}
    \input{./fig/regression-nn2svgp.tex}%
  \end{subfigure}
  \hfill  
  \begin{subfigure}[c]{.01\textwidth}
    \centering
    \tikz[overlay,remember picture]\node(p1){};
  \end{subfigure}  
  \hfill
  \begin{subfigure}[c]{.28\textwidth}
    \raggedleft
    \pgfplotsset{yticklabels={,,},ytick={\empty}}        
    \input{./fig/regression-update.tex}%
  \end{subfigure}
  % 
  \begin{tikzpicture}[remember picture,overlay]
      % Arrow style
    \tikzstyle{myarrow} = [draw=black!80, single arrow, minimum height=14mm, minimum width=2pt, single arrow head extend=4pt, fill=black!80, anchor=center, rotate=0, inner sep=5pt, rounded corners=1pt]
    % Arrows
    \node[myarrow] (p0-arr) at ($(p0) + (1em,1.5em)$) {};
    \node[myarrow] (p1-arr) at ($(p1) + (1em,1.5em)$) {};
    % Arrow labels
    \node[font=\scriptsize\sc,color=white] at (p0-arr) {\our};
    \node[font=\scriptsize\sc,color=white] at (p1-arr) {new data};   
  \end{tikzpicture}
  \end{figure}
    \alert{\bf Regression w/ 2-layers MLP.} Left:~Predictions from the trained neural network. Middle:~Our approach summarizes all the training data with the help of a set of inducing points. The model captures the predictive mean and uncertainty, and (right) makes it possible to incorporate new data without retraining the model.
   \end{minipage}\\[2cm]

    
  \begin{block}{Model \& Methods}

  \heading{Sub-heading}
  
  \begin{itemize}
     \item Item here
     \item Another item
  \end{itemize}
  
  \heading{Another sub-heading}
  
  \begin{itemize}
     \item Item here
     \item Another item
  \end{itemize}

  \end{block}
\end{column}

\separatorcolumn

\begin{column}{\colwidth}
\begin{minipage}{\textwidth}
\begin{figure}[t]
  \centering
  % Set figure size
  \setlength{\figurewidth}{.31\textwidth}
  \setlength{\figureheight}{\figurewidth}
  %
  % Colours
  \definecolor{C0}{HTML}{DF6679}
  \definecolor{C1}{HTML}{69A9CE}
  %
  \begin{tikzpicture}[outer sep=0,inner sep=0]

%    \newcommand{\addfig}[2]{
%    \begin{scope}
%      \clip[rounded corners=3pt] ($(#1)+(-.5\figurewidth,-.5\figureheight)$) rectangle ++(\figurewidth,\figureheight);
%      \node (#2) at (#1) {\includegraphics[width=1.05\figurewidth]{./fig/#2}};
%    \end{scope}
%    %\draw[rounded corners=3pt,line width=1.2pt,black!60] ($(#1)+(-.5\figurewidth,-.5\figureheight)$) rectangle ++(\figurewidth,\figureheight);
%    }
%
%    % The neural network
%    \addfig{0,0}{banana-nn}
    \begin{scope}
      \clip[rounded corners=3pt] ($(0,0)+(-.5\figurewidth,-.5\figureheight)$) rectangle ++(\figurewidth,\figureheight);
      \node (banana-nn) at (0,0) {\includegraphics[width=1.05\figurewidth]{./fig/banana-nn}};
    \end{scope}
    
    % The nn2svgp
    %\addfig{1.1\figurewidth,0}{banana-nn2svgp}
    \begin{scope}
      \clip[rounded corners=3pt] ($(1.1\figurewidth,0)+(-.5\figurewidth,-.5\figureheight)$) rectangle ++(\figurewidth,\figureheight);
      \node (banana-nn2svgp) at (1.1\figurewidth,0) {\includegraphics[width=1.05\figurewidth]{./fig/banana-nn2svgp}};
    \end{scope}
    

    % The update
    %\addfig{2.2\figurewidth,0}{banana-hmc}
    \begin{scope}
      \clip[rounded corners=3pt] ($(2.2\figurewidth,0)+(-.5\figurewidth,-.5\figureheight)$) rectangle ++(\figurewidth,\figureheight);
      \node (banana-hmc) at (2.2\figurewidth,0) {\includegraphics[width=1.05\figurewidth]{./fig/banana-hmc}};
    \end{scope}
	% The arrow
    \tikzstyle{myarrow} = [draw=black!80, single arrow, minimum height=24mm, minimum width=2pt, single arrow head extend=4pt, fill=black!80, anchor=center, rotate=0, inner sep=5pt, rounded corners=1pt]
    \tikzstyle{myblock} = [draw=black!80, minimum height=8mm, minimum width=7mm, fill=black!80, anchor=center, rotate=0, inner sep=5pt, rounded corners=1pt]
    \node[myarrow] (first-arr) at ($(banana-nn)!0.5!(banana-nn2svgp)$) {};
    \node[myblock] (second-arr) at ($(banana-nn2svgp)!0.5!(banana-hmc)$) {};

    % Arrow labels
    \node[font=\scriptsize,color=white] at (first-arr) {\our};
    \node[font=\scriptsize,color=white] at (second-arr) {\normalsize$\bm\approx$};
         
    % Labels
    \node[anchor=north, font=\tiny] at ($(banana-nn) + (0,-.55\figureheight)$) {Neural network prediction};
    \node[anchor=north, font=\tiny] at ($(banana-nn2svgp) + (0,-.55\figureheight)$) {Sparse function-space representation};
    \node[anchor=north, font=\tiny] at ($(banana-hmc) + (0,-.55\figureheight)$) {HMC result as baseline};      
    
  \end{tikzpicture}
  \newcommand{\mycircle}{\protect\tikz[baseline=-.6ex]\protect\node[circle,inner sep=2pt,draw=black,fill=C0,opacity=.5]{};}
  \newcommand{\mysquare}{\protect\tikz[baseline=-.6ex]\protect\node[inner sep=2.5pt,draw=black,fill=C1,opacity=.5]{};}
  \newcommand{\myinducing}{\protect\tikz[baseline=-.7ex]\protect\node[circle,inner sep=1.5pt,draw=black,fill=black]{};}
\end{figure}
\alert{\textbf{Uncertainty quantification for classification}}  (\mysquare~vs.~\mycircle). %We convert the trained neural network (left) to a sparse GP model that summarizes all data onto a sparse set of inducing points~\myinducing (middle). This gives similar behaviour as running full Hamiltonian Monte Carlo (HMC) on the original neural network model weights (right). Marginal uncertainty depicted by colour intensity.
\end{minipage}\\[2cm]
  
  \begin{block}{Background}

  \begin{itemize}
     \item Item here
     \item Another item
  \end{itemize}

  \end{block}

\end{column}

\separatorcolumn
\end{columns}

\begin{columns}
	\begin{column}{2.05\colwidth}
		  \begin{block}{Results and Discussion}

%\begin{minipage}{\textwidth}
%\begin{table}
%  \centering\scriptsize
%  %\caption{Comparisons and ablations on UCI data with negative log predictive density (NLPD\textcolor{gray}{\footnotesize$\pm$std}, lower better). Our sparse \our ($M=256$) is on par with full models (left) and outperforms the GP subset approach of \citet{immer2021improving} (right). Results for methods marked with * as reported in the original benchmark~\citep{immer2021improving}.} %See \cref{app:uci} for additional tables with comparisons.}
%	
%	% Control table spacing
%	\renewcommand{\arraystretch}{1.}
%	\setlength{\tabcolsep}{1.2pt}
%	\setlength{\tblw}{0.083\textwidth}  
%
%    % THE TABLE NUMBER ARE GENERATED BY A SCRIPT	
%	\input{tables/uci.tex}
%\end{table}
\begin{table}[t!]
\resizebox{0.9\textwidth}{!}{
\begin{tabular}{llllllll}
\toprule
model & BNN & GLM & GP Subset (GP) & GP Subset (NN) & NN MAP & SFR (GP) & SFR (NN) \\
dataset &  &  &  &  &  &  &  \\
\midrule
Glass & 0.9562 $\pm$ 0.2649 & 0.8966 $\pm$ 0.1424 & 1.5108 $\pm$ 0.0367 & 1.1420 $\pm$ 0.0738 & 1.8350 $\pm$ 0.6147 & 1.3709 $\pm$ 0.0375 & 1.0922 $\pm$ 0.1363 \\
Waveform & 0.2693 $\pm$ 0.0310 & 0.2676 $\pm$ 0.0227 & 0.2702 $\pm$ 0.0192 & 0.2670 $\pm$ 0.0162 & 0.2670 $\pm$ 0.0162 & 0.2657 $\pm$ 0.0163 & 0.2670 $\pm$ 0.0162 \\
\bottomrule
\end{tabular}
}
\end{table}
\alert{\bf UCI Results.} For now a nice placeholder table that should contain the comparisons and ablations on UCI data with negative log predictive density. %(NLPD\textcolor{gray}{\footnotesize$\pm$std}, lower better). Our sparse our ($M=256$) is on par with full models (left) and outperforms the GP subset approach of \citet{immer2021improving} (right). Results for methods marked with * as reported in the original benchmark~\citep{immer2021improving}. 
%\end{minipage}
  \begin{itemize}
     \item Item here
     \item Another item
  \end{itemize}

  \end{block}


%  \begin{block}{Discussion}
%
%  \begin{itemize}
%     \item Item here
%     \item Another item
%  \end{itemize}
%
%  \end{block}

  \vspace*{1em}

  \nocite{*} % <-- This lists all references that are in the bib file

  \begin{block}{References}
    \vspace*{-.25em}
    \footnotesize{\bibliographystyle{ieeetr}\bibliography{bibliography}}
  \end{block}

	\end{column}
\end{columns}
\end{frame}

\end{document}
